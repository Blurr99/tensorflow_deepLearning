{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3218,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 2393
        },
        {
          "sourceId": 2646,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 1912
        }
      ],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blurr99/tensorflow_deepLearning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'efficientnet/tensorflow2/b0-feature-vector/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F1912%2F2646%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240223%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240223T050430Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D861a2a23f38aeb631e4cb26e0223a51ae35f791a218dc76d70d3d911d561d4bdc19097983fac25f451ad8053a3193c72bd6efbdf1995b38861f795c8f9eee436494c160cfa9ac0fc8b865e64d912bb903e54d05347087034b8db2e5b17a2bb4d1311409e595ea76c835fdaf546b1b5f8e1c51d50b6a12dd68b8e00751fc900983c6b7e826c16a35d9b568a7dc2dd7a81cc92567a9d5dfaa3e30e63818facc2b7f2841228dcc9fb6ac7b83a4bb10af32f23ad47edda5c99b1c5735d4a7ea79d97250a5d673107973550ee724afb88ee316dfa8bbad2ce676fa3efa5006832eb7e4871a84784a3c6ce8687ef6cc046f977feb028335d1be649ea72a07e55abf419,resnet-v2/tensorflow2/50-feature-vector/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F2393%2F3218%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240223%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240223T050430Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dabca387864915e6061553f3eea6a6a6ac501017859b484bf86e8a65f8285135f8e20324b9b66d8c7ea22df1d0c52d78e06b3baf288654617e5afb83b7bac182d91481c57eb43b5f8c1fb31f3f51d2a93c65c096b562e0c72f1b1a22cb8756b4f486650a46a3a3f73df5e33df1c5649f7a346818741faddc97aec3a4817091c110c1e68685360a7b1d92c97c8a3c90c23393e6cebedc8a9e88345cea0866042bcf7f3bf979ede36d3bbe2221b2b22a7024785ac92937e1ab7d320b78806cab5b07175798411f92d15af09bd89c5df1ea67ef0f29294ba1c5cbc21b5db7f8983daae60c5db0764b397c5d8894813dcfc77aa234e9f2350ae46f1b50b09714a28c9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "nEWV0CNBWc1U"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-11-24T20:20:59.955095Z",
          "iopub.execute_input": "2023-11-24T20:20:59.955842Z",
          "iopub.status.idle": "2023-11-24T20:20:59.969542Z",
          "shell.execute_reply.started": "2023-11-24T20:20:59.955807Z",
          "shell.execute_reply": "2023-11-24T20:20:59.968504Z"
        },
        "trusted": true,
        "id": "EydlpB_hWc1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "\n",
        "Transfer Learning is leveraging a working model's existing architecture and learned patterns for a custom problem.\n",
        "\n",
        "There are 2 main benefits:\n",
        "1. Can leverage an existing model's architecture that is proven to works on problems similar to the custom problem.\n",
        "2. Can leverage a working neural architecture which has already learned data to our own, then those patterns can be adapted to the custom data."
      ],
      "metadata": {
        "id": "CMhWnAzWWc1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:20:59.971383Z",
          "iopub.execute_input": "2023-11-24T20:20:59.971656Z",
          "iopub.status.idle": "2023-11-24T20:21:01.129163Z",
          "shell.execute_reply.started": "2023-11-24T20:20:59.971632Z",
          "shell.execute_reply": "2023-11-24T20:21:01.128Z"
        },
        "trusted": true,
        "id": "Dbkh759JWc1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and exploring the data"
      ],
      "metadata": {
        "id": "_OFGkAKQWc1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the data (10% of 10 food classes data)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:01.130922Z",
          "iopub.execute_input": "2023-11-24T20:21:01.131272Z",
          "iopub.status.idle": "2023-11-24T20:21:04.607573Z",
          "shell.execute_reply.started": "2023-11-24T20:21:01.131242Z",
          "shell.execute_reply": "2023-11-24T20:21:04.606408Z"
        },
        "trusted": true,
        "id": "2DnDSRpuWc1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "    print(f\"In {dirpath}, there are {len(dirnames)} directories and {len(filenames)} images\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:04.609839Z",
          "iopub.execute_input": "2023-11-24T20:21:04.610182Z",
          "iopub.status.idle": "2023-11-24T20:21:04.622036Z",
          "shell.execute_reply.started": "2023-11-24T20:21:04.61015Z",
          "shell.execute_reply": "2023-11-24T20:21:04.620994Z"
        },
        "trusted": true,
        "id": "FDTI68JKWc1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def plot_random(target_dir, target_class):\n",
        "    target_folder = target_dir + \"/\" + target_class\n",
        "\n",
        "    random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "    plt.imshow(img)\n",
        "    plt.axis(False)\n",
        "    plt.title(target_class)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:04.623327Z",
          "iopub.execute_input": "2023-11-24T20:21:04.623659Z",
          "iopub.status.idle": "2023-11-24T20:21:04.63081Z",
          "shell.execute_reply.started": "2023-11-24T20:21:04.623628Z",
          "shell.execute_reply": "2023-11-24T20:21:04.629874Z"
        },
        "trusted": true,
        "id": "s2qTrVPIWc1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random(\"/kaggle/working/10_food_classes_10_percent/train\", \"chicken_curry\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:04.631975Z",
          "iopub.execute_input": "2023-11-24T20:21:04.632312Z",
          "iopub.status.idle": "2023-11-24T20:21:04.955907Z",
          "shell.execute_reply.started": "2023-11-24T20:21:04.632281Z",
          "shell.execute_reply": "2023-11-24T20:21:04.954894Z"
        },
        "trusted": true,
        "id": "BVHTd_3RWc1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "Using the `ImageDataGenerator` class to load in the images into batches."
      ],
      "metadata": {
        "id": "Mj8cBjvpWc1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"/kaggle/working/10_food_classes_10_percent/train\"\n",
        "test_dir = \"/kaggle/working/10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "print(\"Training Images\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                         target_size = IMAGE_SHAPE,\n",
        "                                                         batch_size = BATCH_SIZE,\n",
        "                                                         class_mode = \"categorical\")\n",
        "\n",
        "print(\"Testing Images\")\n",
        "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
        "                                                       target_size = IMAGE_SHAPE,\n",
        "                                                        batch_size = BATCH_SIZE,\n",
        "                                                        class_mode = \"categorical\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:04.957245Z",
          "iopub.execute_input": "2023-11-24T20:21:04.957602Z",
          "iopub.status.idle": "2023-11-24T20:21:05.093563Z",
          "shell.execute_reply.started": "2023-11-24T20:21:04.957572Z",
          "shell.execute_reply": "2023-11-24T20:21:05.092739Z"
        },
        "trusted": true,
        "id": "evGw-YAqWc1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst the model trains)\n",
        "\n",
        "Callbacks are extra functionalities that can be added to models to be performed during or after training. Some of the most popular callbacks are:\n",
        "* Tracking experiments with the TensorBoard callback.\n",
        "* Model checkpoint with the ModelCheckpoints callback.\n",
        "* Stopping a model from training before it trains too long with the EarlyStopping callback."
      ],
      "metadata": {
        "id": "V9oiTaDYWc1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "    log_dir = dir_name +\"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
        "    print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "    return tensorboard_callback"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:05.094584Z",
          "iopub.execute_input": "2023-11-24T20:21:05.094871Z",
          "iopub.status.idle": "2023-11-24T20:21:05.100097Z",
          "shell.execute_reply.started": "2023-11-24T20:21:05.094845Z",
          "shell.execute_reply": "2023-11-24T20:21:05.099103Z"
        },
        "trusted": true,
        "id": "2W_wSgX-Wc1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "Instead of using TensorFlow to create models layer by layer from scratch, using TensorFlowHub to get the model's layers.\n",
        "\n",
        "Pretrained models can be accessed from: https://www.kaggle.com/models.\n",
        "\n",
        "Using the following feature vector model: \"https://www.kaggle.com/models/google/efficientnet/frameworks/TensorFlow1/variations/b0-feature-vector/versions/1\", found after browsing tensorflowhub."
      ],
      "metadata": {
        "id": "0-NnQdbaWc1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the following 2 models:\n",
        "resnet_url = \"https://kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-feature-vector/versions/1\"\n",
        "\n",
        "efficientnet_url = \"https://www.kaggle.com/models/google/efficientnet/frameworks/TensorFlow2/variations/b0-feature-vector/versions/1\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:05.103123Z",
          "iopub.execute_input": "2023-11-24T20:21:05.103387Z",
          "iopub.status.idle": "2023-11-24T20:21:05.113602Z",
          "shell.execute_reply.started": "2023-11-24T20:21:05.103363Z",
          "shell.execute_reply": "2023-11-24T20:21:05.112904Z"
        },
        "trusted": true,
        "id": "5uaJVWi7Wc1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:05.11484Z",
          "iopub.execute_input": "2023-11-24T20:21:05.115447Z",
          "iopub.status.idle": "2023-11-24T20:21:05.125623Z",
          "shell.execute_reply.started": "2023-11-24T20:21:05.11542Z",
          "shell.execute_reply": "2023-11-24T20:21:05.124896Z"
        },
        "trusted": true,
        "id": "dOl57IjeWc1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a create_model() function to create a model from a URL\n",
        "def create_model(model_URL, num_classes = 10):\n",
        "    \"\"\"\n",
        "        Takes a TensorFlow Hub URL, and creates a Keras Sequential model with it.\n",
        "\n",
        "        Args:\n",
        "            model_URL (str): A TensorFlow Hub feature extraction URL.\n",
        "            num_classes (int): Number of output neurons in the output layer,\n",
        "            should be euqal to number of target classes (default = 10).\n",
        "\n",
        "        Returns:\n",
        "            An uncompiled Keras Sequential model with model_url as feature extraction layer\n",
        "            and Dense output layer with num_classes output layer.\n",
        "    \"\"\"\n",
        "    # Download the prettrained model and asve it as a Keras layer\n",
        "    handle = model_URL\n",
        "    feature_extraction_layer = hub.KerasLayer(handle = handle,\n",
        "                                             trainable= False, # Freeze the already trained patterns\n",
        "                                             name = \"feature_extraction_layer\",\n",
        "                                             input_shape = IMAGE_SHAPE + (3,))\n",
        "\n",
        "    # Create a model\n",
        "    model = tf.keras.Sequential([\n",
        "        feature_extraction_layer,\n",
        "        layers.Dense(num_classes, activation = \"softmax\", name = \"output_layer\")\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:05.126904Z",
          "iopub.execute_input": "2023-11-24T20:21:05.127706Z",
          "iopub.status.idle": "2023-11-24T20:21:05.13933Z",
          "shell.execute_reply.started": "2023-11-24T20:21:05.127669Z",
          "shell.execute_reply": "2023-11-24T20:21:05.138618Z"
        },
        "trusted": true,
        "id": "az2X-Q3eWc1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing ResNet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "uUZl66fYWc1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create resnet model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                           num_classes = train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:05.140396Z",
          "iopub.execute_input": "2023-11-24T20:21:05.140658Z",
          "iopub.status.idle": "2023-11-24T20:21:07.713477Z",
          "shell.execute_reply.started": "2023-11-24T20:21:05.140633Z",
          "shell.execute_reply": "2023-11-24T20:21:07.712458Z"
        },
        "trusted": true,
        "id": "poCXUySPWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:07.714709Z",
          "iopub.execute_input": "2023-11-24T20:21:07.715054Z",
          "iopub.status.idle": "2023-11-24T20:21:07.742761Z",
          "shell.execute_reply.started": "2023-11-24T20:21:07.715026Z",
          "shell.execute_reply": "2023-11-24T20:21:07.741932Z"
        },
        "trusted": true,
        "id": "NYtP-NELWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "resnet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                    optimizer = tf.keras.optimizers.Adam(),\n",
        "                    metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:07.743858Z",
          "iopub.execute_input": "2023-11-24T20:21:07.744162Z",
          "iopub.status.idle": "2023-11-24T20:21:07.756196Z",
          "shell.execute_reply.started": "2023-11-24T20:21:07.744138Z",
          "shell.execute_reply": "2023-11-24T20:21:07.755317Z"
        },
        "trusted": true,
        "id": "byZcrQXaWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                epochs = 5,\n",
        "                steps_per_epoch = len(train_data_10_percent),\n",
        "                validation_data = test_data_10_percent,\n",
        "                validation_steps = len(test_data_10_percent),\n",
        "                callbacks = [create_tensorboard_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                        experiment_name = \"resnet50v2\")])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:07.757489Z",
          "iopub.execute_input": "2023-11-24T20:21:07.758284Z",
          "iopub.status.idle": "2023-11-24T20:21:59.460136Z",
          "shell.execute_reply.started": "2023-11-24T20:21:07.75825Z",
          "shell.execute_reply": "2023-11-24T20:21:59.459334Z"
        },
        "trusted": true,
        "id": "KOeKC0G8Wc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transfer learning frature extractor model out performed ALL of the previous models (substantially) and in a quicker time AND with only 10% of the training dataset."
      ],
      "metadata": {
        "id": "nNxuVV0WWc1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to plot the loss curves\n",
        "def plot_loss_curves(history):\n",
        "    \"\"\"\n",
        "        Returns separate loss curves for training and validation sets.\n",
        "\n",
        "        Args:\n",
        "            history: TensorFlow history object\n",
        "\n",
        "        Returns:\n",
        "            Plots of training/validation, loss and accuracy metrics\n",
        "    \"\"\"\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    accuracy = history.history[\"accuracy\"]\n",
        "    val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "    epochs = range(len(accuracy))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, label = \"Training loss\")\n",
        "    plt.plot(epochs, val_loss, label = \"Validation loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label = \"Training Accuracy\")\n",
        "    plt.plot(epochs, val_accuracy, label = \"Validation Accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:59.461411Z",
          "iopub.execute_input": "2023-11-24T20:21:59.46177Z",
          "iopub.status.idle": "2023-11-24T20:21:59.469783Z",
          "shell.execute_reply.started": "2023-11-24T20:21:59.46174Z",
          "shell.execute_reply": "2023-11-24T20:21:59.468913Z"
        },
        "trusted": true,
        "id": "OywMd6vSWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:21:59.471059Z",
          "iopub.execute_input": "2023-11-24T20:21:59.471336Z",
          "iopub.status.idle": "2023-11-24T20:22:00.226249Z",
          "shell.execute_reply.started": "2023-11-24T20:21:59.471312Z",
          "shell.execute_reply": "2023-11-24T20:22:00.22544Z"
        },
        "trusted": true,
        "id": "T6KsUi-BWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T17:08:14.752825Z",
          "iopub.execute_input": "2023-11-24T17:08:14.753636Z",
          "iopub.status.idle": "2023-11-24T17:08:14.757735Z",
          "shell.execute_reply.started": "2023-11-24T17:08:14.753602Z",
          "shell.execute_reply": "2023-11-24T17:08:14.756658Z"
        },
        "id": "wiOxcx92Wc1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an efficientnet model\n",
        "efficientNet_model = create_model(model_URL=efficientnet_url,\n",
        "                                  num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:22:00.227587Z",
          "iopub.execute_input": "2023-11-24T20:22:00.227956Z",
          "iopub.status.idle": "2023-11-24T20:22:09.736289Z",
          "shell.execute_reply.started": "2023-11-24T20:22:00.227925Z",
          "shell.execute_reply": "2023-11-24T20:22:09.735308Z"
        },
        "trusted": true,
        "id": "5HkCNZzJWc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientNet_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:22:09.737644Z",
          "iopub.execute_input": "2023-11-24T20:22:09.738017Z",
          "iopub.status.idle": "2023-11-24T20:22:09.768812Z",
          "shell.execute_reply.started": "2023-11-24T20:22:09.737981Z",
          "shell.execute_reply": "2023-11-24T20:22:09.767758Z"
        },
        "trusted": true,
        "id": "ZLzNZVUzWc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "efficientNet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                           optimizer = tf.keras.optimizers.Adam(),\n",
        "                           metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:22:09.770198Z",
          "iopub.execute_input": "2023-11-24T20:22:09.771004Z",
          "iopub.status.idle": "2023-11-24T20:22:09.783486Z",
          "shell.execute_reply.started": "2023-11-24T20:22:09.770935Z",
          "shell.execute_reply": "2023-11-24T20:22:09.782676Z"
        },
        "trusted": true,
        "id": "gcsqr6RAWc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "efficient_history = efficientNet_model.fit(train_data_10_percent,\n",
        "                                           epochs = 5,\n",
        "                                           steps_per_epoch = len(train_data_10_percent),\n",
        "                                           validation_data = test_data_10_percent,\n",
        "                                           validation_steps = len(test_data_10_percent),\n",
        "                                          callbacks= [create_tensorboard_callback(\"tensorflow_hub\",\n",
        "                                                                                 experiment_name=\"efficientnetb0v1\")])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:22:09.784765Z",
          "iopub.execute_input": "2023-11-24T20:22:09.785426Z",
          "iopub.status.idle": "2023-11-24T20:23:02.99161Z",
          "shell.execute_reply.started": "2023-11-24T20:22:09.785388Z",
          "shell.execute_reply": "2023-11-24T20:23:02.990803Z"
        },
        "trusted": true,
        "id": "xajcBD2MWc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(efficient_history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:23:02.993228Z",
          "iopub.execute_input": "2023-11-24T20:23:02.993524Z",
          "iopub.status.idle": "2023-11-24T20:23:03.688709Z",
          "shell.execute_reply.started": "2023-11-24T20:23:02.993497Z",
          "shell.execute_reply": "2023-11-24T20:23:03.687725Z"
        },
        "trusted": true,
        "id": "0fgQ1O7TWc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different types of Transfer Learning\n",
        "\n",
        "* \"As is\" transfer learning - using an existing model with no changes what so ever (e.g. using ImageNet model on 1000 ImageNet classes)\n",
        "* \"Feature Extraction\" transfer learning - use the prelearned patterns of an existing model (e.g. EfficientNetB0 trained on ImageNet) and adjust the output layer for a custom problem (e.g. 1000 classes -> 10 classes of food)\n",
        "* \"Fine-Tuning\" transfer learning - use the prelearned patterns of an existing model and fine turn many or all of the underlying layers (including new output layers)"
      ],
      "metadata": {
        "id": "zBhmN7IAWc1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:23:25.111981Z",
          "iopub.execute_input": "2023-11-24T20:23:25.11296Z",
          "iopub.status.idle": "2023-11-24T20:23:37.387599Z",
          "shell.execute_reply.started": "2023-11-24T20:23:25.11291Z",
          "shell.execute_reply": "2023-11-24T20:23:37.386509Z"
        },
        "trusted": true,
        "id": "l5M9VoYIWc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload TensorBoard dev records\n",
        "import subprocess\n",
        "\n",
        "# Define the TensorBoard Dev upload command\n",
        "command = [\n",
        "    \"tensorboard\",\n",
        "    \"dev\",\n",
        "    \"upload\",\n",
        "    \"--logdir\",\n",
        "    \"./tensorflow_hub/\",\n",
        "    \"--name\",\n",
        "    \"EfficientNetB0 vs. ResNet50v2\",\n",
        "    \"--description\",\n",
        "    \"Comparing two different TF hub feature extraction model architectures using 10% of the training data\",\n",
        "    \"--one_shot\",\n",
        "]\n",
        "\n",
        "# Run the command and provide 'y' as input to confirm\n",
        "process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "output, error = process.communicate(input='y')\n",
        "\n",
        "# Print the output and error for debugging (optional)\n",
        "print(\"Output:\", output)\n",
        "print(\"Error:\", error)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-24T20:27:58.871302Z",
          "iopub.execute_input": "2023-11-24T20:27:58.871694Z"
        },
        "trusted": true,
        "id": "MrA1qAs0Wc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFp2iI_GWc1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}